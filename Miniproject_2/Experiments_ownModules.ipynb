{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride = 1 )\n",
    "x = torch.randn((100, in_channels, 32, 32))\n",
    "y = torch.randn((100, in_channels, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(a, weight, bias, kernel, inc, outc) :\n",
    "    n = a.size(0)\n",
    "    stride = (1,1)\n",
    "    dilation = (1,1)\n",
    "    padding = (0,0)\n",
    "    print(weight.view(-1, weight.size(0)).size())\n",
    "    unfold_a = torch.nn.functional.unfold(a, kernel_size = kernel, stride = stride, padding = padding, dilation = dilation)\n",
    "    h_out = math.floor(1 + (a.size(2) + 2 * padding[0] - dilation[0] * (kernel[0] - 1 ) - 1)/stride[0])\n",
    "    w_out = math.floor(1 + (a.size(3) + 2 * padding[1] - dilation[1] * (kernel[1] - 1 ) - 1)/stride[1])\n",
    "    print(\"Unfold size:\",unfold_a.size())\n",
    "    print(\"Weight size:\",weight.view(outc,-1).size())\n",
    "    print(\"Bias size:\",bias.view(1,-1,1).size())\n",
    "    print((weight.view(outc,-1) @ unfold_a).size())\n",
    "    return (weight.view(outc,-1) @ unfold_a + bias.view(1,-1,1)).view(n, outc, h_out, w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 10])\n",
      "Unfold size: torch.Size([100, 12, 961])\n",
      "Weight size: torch.Size([10, 12])\n",
      "Bias size: torch.Size([1, 10, 1])\n",
      "torch.Size([100, 10, 961])\n"
     ]
    }
   ],
   "source": [
    "result_our_conv = convolve(x,conv.weight,conv.bias,kernel_size,in_channels,out_channels)\n",
    "result_pytorch_conv = conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(conv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 2, 2]), torch.Size([10]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].size(),l[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_allclose(result_pytorch_conv, result_our_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride = 1 )\n",
    "conv1 = torch.nn.Conv2d (in_channels, out_channels, kernel_size, stride = 1 )\n",
    "s = torch.nn.Sequential(conv,conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [(torch.empty(2,2).fill_(1),torch.empty(2,2).normal_())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[1., 1.],\n",
       "          [1., 1.]]),\n",
       "  tensor([[-0.8852, -2.3041],\n",
       "          [ 0.7805, -0.8119]]))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (p,g) in parameters:\n",
    "    g.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[1., 1.],\n",
       "          [1., 1.]]),\n",
       "  tensor([[0., 0.],\n",
       "          [0., 0.]]))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
